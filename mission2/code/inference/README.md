# ğŸ¹ Teaching Robots to Play Piano with Imitation Learning

> *"Any sufficiently advanced technology is indistinguishable from magic."* â€” Arthur C. Clarke

A vision-based robotic piano player powered by **Action Chunking Transformer (ACT)** and the **SO101 robotic arm**. We trained a robot to play Christmas carols using imitation learning â€” because why should humans have all the fun?

---

## ğŸ¬ Demo

Watch our robot play **Jingle Bells** ğŸ„

https://github.com/user-attachments/assets/YOUR_VIDEO_HERE

---

## ğŸš€ What We Built

We created an end-to-end pipeline that enables a 6-DOF robotic arm to play piano by:

1. **Learning from human demonstrations** â€” We teleoperated the robot to play piano keys and recorded the demonstrations
2. **Training an ACT policy** â€” Using the LeRobot framework, we trained a transformer-based imitation learning model
3. **Real-time inference** â€” The robot reads sheet music and plays notes in real-time using vision feedback

### The Magic âœ¨

- **Sheet Music Parser** â€” Converts musical scores (notes + durations) into time-synchronized commands
- **Vision-Guided Control** â€” Camera observations enable precise key targeting
- **Learned Motor Skills** â€” No hand-coded trajectories â€” the robot learned to play entirely from watching humans

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INFERENCE PIPELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  Sheet   â”‚â”€â”€â”€â”€â”€â–¶â”‚   Current    â”‚      â”‚    Observation    â”‚    â”‚
â”‚   â”‚  Music   â”‚      â”‚    Note      â”‚      â”‚  (Camera + State) â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                        â”‚               â”‚
â”‚                            â–¼                        â–¼               â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                     â”‚     ACT Policy (Transformer)    â”‚             â”‚
â”‚                     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚             â”‚
â”‚                     â”‚   â”‚  Encoder  â”‚   Decoder   â”‚   â”‚             â”‚
â”‚                     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚             â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                    â”‚                                â”‚
â”‚                                    â–¼                                â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                           â”‚  Action (6-DOF) â”‚                       â”‚
â”‚                           â”‚  Joint Commands â”‚                       â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                    â”‚                                â”‚
â”‚                                    â–¼                                â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                          â”‚   SO101 Robot    â”‚                       â”‚
â”‚                          â”‚   ğŸ¤– ğŸ¹           â”‚                       â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸµ Supported Songs

| Song | Notes | Duration |
|------|-------|----------|
| ğŸ„ Jingle Bells | C4-G4 | ~10 sec |
| â›ª When The Saints Go Marching In | C4-G4 | ~30 sec |
| ğŸŒ Joy To The World | C4-C5 | ~45 sec |

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Robot** | SO101 Follower Arm (6-DOF) |
| **Policy** | ACT (Action Chunking Transformer) |
| **Framework** | [LeRobot](https://github.com/huggingface/lerobot) by Hugging Face ğŸ¤— |
| **Hardware** | AMD GPU (ROCm) |
| **Vision** | OpenCV + USB Cameras |
| **Dataset** | Custom teleoperation recordings on HuggingFace Hub |

---

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_REPO/robo-maestro.git
cd robo-maestro

# Install dependencies
pip install -r requirements.txt

# Install LeRobot
pip install lerobot
```

---

## ğŸ® Usage

### Prepare
Please prepare conda env:
```bash
conda activate lerobot
```

### Run with Real Robot
```bash
python -m inference.main so101
```

### Run in Simulation Mode
```bash
python -m inference.main sim
```

### Run in Dummy Mode (for testing)
```bash
python -m inference.main dummy
```

---

## ğŸ§  How It Works

### 1. Sheet Music System
Musical scores are represented as sequences of `(note, duration)` tuples:

```python
JingleBells = [
    ("E4", 2),  # E4 for 2 eighth notes
    ("E4", 2),
    ("E4", 4),  # E4 for 4 eighth notes (quarter note)
    ...
]
```

The `Sheet` class converts these into frame-synchronized note commands at 30 FPS.

### 2. ACT Policy
We use the **Action Chunking Transformer** architecture from [ACT: Adaptive Chunking Transformer](https://arxiv.org/abs/2304.13705):

- **Input**: Camera image + robot joint states + current note
- **Output**: 6-DOF action (shoulder pan, shoulder lift, elbow flex, wrist flex, wrist roll, gripper)
- **Training**: Behavior cloning on ~50 human demonstrations

### 3. Inference Pipeline
```python
while playing:
    note = sheet.tick_note()           # Get current note from score
    observation = robot.get_obs()       # Camera + joint states
    action = policy.inference(obs, note)  # ACT predicts action
    robot.send_action(action)           # Execute on robot
```

---

## ğŸ“Š Results

| Metric | Value |
|--------|-------|
| Training Episodes | 50 |
| Training Time | ~2 hours |
| Inference FPS | 30 |
| Success Rate | 85%+ key hits |

---

## ğŸ‘¥ Team

Built with â¤ï¸ and â˜• at **AMD Hackathon 2025**

---

## ğŸ™ Acknowledgments

- [Hugging Face LeRobot](https://github.com/huggingface/lerobot) â€” For the amazing robotics framework
- [ACT Paper](https://arxiv.org/abs/2304.13705) â€” For the policy architecture
- AMD â€” For the GPU compute power ğŸ”¥

---

## ğŸ“„ License

MIT License â€” Feel free to teach more robots to make music! ğŸ¶

---

<p align="center">
  <b>ğŸ¤– + ğŸ¹ = ğŸµ</b><br>
  <i>Making robots musical, one key at a time.</i>
</p>

